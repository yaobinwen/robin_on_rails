% Regarding `oneside` (https://stackoverflow.com/a/8371473/630364):
%
% `oneside` removes the blank pages between chapters.
% "Note that this method make the margins of all the pages the same. In
% `twoside`, the margins are different for the odd and the even pages".
\documentclass[12pt, letterpaper, oneside]{book}
\usepackage{amsmath}
\usepackage[letterpaper, textwidth=7.5in, textheight=8in]{geometry}
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  filecolor=magenta,
  urlcolor=blue,
}

\title{Notes on \textit{Linear Algebra Done Right}}
\author{Yaobin Wen}
\date{January 2023}

\begin{document}

\maketitle
\tableofcontents

\chapter*{Overview}
\addcontentsline{toc}{chapter}{Overview}

This document contains my study notes of the textbook \textit{Linear Algebra
Done Right}. I use it for a few purposes:

\begin{enumerate}
  \item As a reference to quickly refresh my memory on the subjects.
  \item Keep the notes to help me understand the text that is not obvious for
    me to comprehend.
\end{enumerate}

% =============================================================================
%
% Chapter: Review of Real Numbers
%
% =============================================================================

\chapter*{Review of Real Numbers}
\addcontentsline{toc}{chapter}{Review of Real Numbers}

(TODO)

% =============================================================================
%
% Chapter 1: Vector Spaces
%
% =============================================================================

\chapter{Vector Spaces}

% ------------------------------
\section{Overview}
% ------------------------------

This chapter starts with the definition of \emph{complex numbers} because
complex numbers are a superset of real numbers. Once we properly define complex
numbers, we can focus on them because the properties will also hold for real
numbers. "In linear algebra," as the textbook says, "better theorems and more
insight emerge if complex numbers are investigated along with real numbers."

A complex number is an element of a \emph{list}, and a list is used to denote a
\emph{vector}, and vectors make up \emph{vector spaces}. Therefore, after
complex numbers are discussed, we will move onto defining lists, vectors, and
vector spaces.

% ------------------------------
\section{Review Questions}
% ------------------------------

(See the end of this chapter for the review question answers.)

\begin{enumerate}
  \item What is a vector space?
  \item What is the relationship between $\mathbf{F^n}$ and the vector space
    $V$?
  \item In a vector space $V$, for $u, v \in V$, what is the relationship
    between $u \cdot v$ and $v \cdot u$?
  \item In a vector space $V$, for $u, v, w \in V$, what is the relationship
  between $(u \cdot v) \cdot w$ and $u \cdot (v \cdot w)$?
  \item When talking about the vector space $V$ as the textbook defines it, why
    is it important to specify that it depends on the set $F$? What role does
    $\mathbf{F}$ play in the definition of $V$?
  \item What is $\mathbf{F}^S$?
  \item In the definition of $\mathbf{F}^S$, what does $S$ stand for? What is
    an element in $\mathbf{F}^S$?
  \item Does the definition of $\mathbf{F}^S$ imply that the function
    $0: S \rightarrow \mathbf{F}$ is an element in $\mathbf{F}^S$? Why or why
    not?
  \item In section ``1.29 The number 0 times a vector'', the textbook proves
    the property $0v = 0$ for every $v \in V$ without using the scalar
    multiplication in $\mathbf{F}^n$ in section 1.17. Why not use that? Should
    it have been used, the proof would have been much more simple, wouldn't it?
  \item What is a subspace?
  \item What are the conditions for the subset $U$ to satisfy in order to make
    it a subspace of $V$?
  \item Among all the conditions that $U$ must satisfy, what about the
    multiplicative identity $1$?
\end{enumerate}

% ------------------------------
\section{1.1 Definition: Complex numbers}
% ------------------------------

We {define} a \textbf{\emph{complex number}} as follows (see
``1.1 Definition''):

\begin{itemize}
  \item A complex number is an ordered pair $(a, b)$, where $a, b \in
    \mathbf{R}$, but we will write this as $a + bi$.
    \begin{itemize}
      \item When $a, b \in \mathbf{R}$ and $b = 0$, we have all the real
        numbers $\mathbf{R}$. Thus $\mathbf{R} \subset \mathbf{C}$.
    \end{itemize}
  \item The set of all complex numbers is denoted by $\mathbf{C}$:
    \[ \mathbf{C} = \{a + bi: a, b \in \mathbf{R}\} \]
  \item \textbf{Addition}: Let $\alpha = (a + bi)$, $\beta = (c + di)$, where
    $a, b, c, d \in \mathbf{R}$, we have:
    \[ \alpha + \beta = (a + bi) + (c + di) = (a + c) + (b + d)i \]
    \begin{itemize}
      \item This also tells us that if $\alpha, \beta \in \mathbf{C}$, then
        $\alpha + \beta \in \mathbf{C}$
    \end{itemize}
  \item \textbf{Multiplication}: Let $\alpha = (a + bi)$, $\beta = (c + di)$,
    where $a, b, c, d \in \mathbf{R}$, we have:
    \[ \alpha\beta = (a + bi)(c + di) = (ac - bd) + (ad + bc)i \]
    \begin{itemize}
      \item This also tells us that if $\alpha, \beta \in \mathbf{C}$, then
        $\alpha\beta \in \mathbf{C}$
    \end{itemize}
\end{itemize}

% ------------------------------
\section{1.3 Properties of complex arithmetic}
% ------------------------------

The following properties can be proved according to the definition of complex
numbers and the addition and multiplication:

\begin{itemize}
  \item \textbf{commutativity}:
    \[
      \alpha + \beta = \beta + \alpha \quad and \quad \alpha\beta\ =
      \beta\alpha \quad for \; all \; \alpha, \beta \in \mathbf{C}
    \]
  \item \textbf{associativity}:
    \[
      (\alpha + \beta) + \lambda = \alpha + (\beta + \lambda) \quad and \quad
      (\alpha\beta)\lambda = \alpha(\beta\lambda) \quad for \; all \; \alpha,
      \beta, \lambda \in \mathbf{C}
    \]
  \item \textbf{identities}:
    \[
      \lambda + 0 = \lambda \ and \ \lambda1 = \lambda \ for \ all \ \lambda
      \in \mathbf{C}
    \]
    \begin{itemize}
      \item Note that here $0, 1 \in \mathbf{R}$
    \end{itemize}
  \item \textbf{additive inverse}:
    \[
      For \ every \ \alpha \in \mathbf{C}, there \ exists \ a \ unique \ \beta
      \in \mathbf{C} \ such \ that \ \alpha + \beta = 0
    \]
    \begin{itemize}
      \item Note that here $0 \in \mathbf{R}$
    \end{itemize}
  \item \textbf{multiplicative inverse}:
    \[
      For \ every \ \alpha \in \mathbf{C} \ with \ \alpha \neq 0, there \
      exists \ a \ unique \ \beta \in \mathbf{C} \newline such \ that \
      \alpha\beta = 1
    \]
    \begin{itemize}
      \item Note that here $1 \in \mathbf{R}$
    \end{itemize}
  \item \textbf{distributive property}:
    \[
      \lambda(\alpha + \beta) = \lambda\alpha + \lambda\beta \ for \ all \
      \lambda, \alpha, \beta \in \mathbf{C}
    \]
\end{itemize}

NOTE(ywen): Complex numbers are defined based upon real numbers. In order to
prove the properties of complex arithmetic, we need to use the properties of
real arithmetic (i.e., communtativity, associativity, etc. for real numbers).
Example 1.4 shows this method.

% ------------------------------
\section{1.5 Definition: $-\alpha$, subtraction, $1/\alpha$, division}
% ------------------------------

Let $\alpha, \beta \in \mathbf{C}$:

\begin{itemize}
  \item ``$-\alpha$'' is the additive inverse of $\alpha$ such that
    \[ \alpha + (-\alpha) = 0 \]
    \begin{itemize}
      \item Note that here $0 \in \mathbf{R}$
    \end{itemize}
  \item \textbf{\textit{Subtraction}} on $\mathbf{C}$ is defined by
    \[ \beta - \alpha = \beta + (-\alpha) \]
  \item For $\alpha \neq 0$, define $1/\alpha$ as the \textbf{multiplicative
    inverse} of $\alpha$ such that
    \[ \alpha(1/\alpha) = 1 \]
    \begin{itemize}
      \item Note that here $1 \in \mathbf{R}$
    \end{itemize}
  \item \textbf{\textit{Division}} on $\mathbf{C}$ is defined by
    \[ \beta/\alpha = \beta(1/\alpha) \]
    \begin{itemize}
      \item Note that here $1 \in \mathbf{R}$
    \end{itemize}
\end{itemize}

% ------------------------------
\section{1.6 Notation F}
% ------------------------------

$\mathbf{F}$ stands for either $\mathbf{R}$ or $\mathbf{C}$.

But because $\mathbf{C}$ is a superset of $\mathbf{R}$, when we think of
$\mathbf{F}$, we can basically think of it as $\mathbf{C}$.

% ------------------------------
\section{1.6.1 Definition: $\alpha^m$}
% ------------------------------

For $\alpha \in \mathbf{F}$ and $m \in \mathbf{N}$:

\[ \alpha^m = \underbrace{\alpha\cdot\cdot\cdot\alpha}_{m \ times} \]

Thus for all $\alpha, \beta \in \mathbf{F}$, $m, n \in \mathbf{N}$:

\begin{itemize}
  \item $(\alpha^m)^n = \alpha^{mn}$
  \item $(\alpha\beta)^m = \alpha^m\beta^m$
\end{itemize}

% ------------------------------
\section{1.8 Definition: \textit{list}, \textit{length}}
% ------------------------------

For $n \in \mathbf{N}$, a \textbf{\textit{list}} of \textbf{\textit{length n}}
is an \textbf{ordered} collection of \textit{n} \textbf{elements}. It's denoted
as follows: \[ (x_1, x_2, ..., x_n) \]

Note that:
\begin{itemize}
  \item A list has a \textbf{finite} length.
  \item An element can be anything: a number, another list, a text string, etc.
  \item A list of length 0 is denoted as ``$()$''.
  \item A list of length n is also called an \textit{n-\textbf{tuple}}.
\end{itemize}

Two lists $(x_1, x_2, ..., x_n)$ and $(y_1, y_2, ..., y_m)$ are equal if and
only if:
\begin{itemize}
  \item $n = m$
  \item $x_i = y_i$ for $i = 1, 2, ..., n$
\end{itemize}

% ------------------------------
\section{Lists and Sets}
% ------------------------------

Table compares lists and sets:
\begin{table}[ht!]
\centering
\begin{tabular}{||c c c ||} 
 \hline
   & Lists & Sets \\ [0.5ex] 
 \hline
 \hline
 Length & Finite & Finite or infinite \\ 
 Order & Matters & Doesn't matter \\
 Repetition & Allows & Doesn't allow \\ [1ex]
 \hline
\end{tabular}
\caption{Compare lists and sets}
\label{table:lists_sets_comp}
\end{table}

% ------------------------------
\section{1.10 Definition: $\mathbf{F^n}$ and $0$}
% ------------------------------

We use $\mathbf{F}$ to denote either $\mathbf{R}$ or $\mathbf{C}$.

We define $\mathbf{F^n}$ as the set of all lists of length $n$ of elements of
$\mathbf{F}$:

\[
  \mathbf{F^n} = \{(x_1, ..., x_n): x_j \in \mathbf{F} \ for \ j = 1, ..., n\}
\]

We say $x_j$ is the $j^{th}$ \textbf{\textit{coordinate}} of $(x_1, ..., x_n)$.

Let $\mathbf{0}$ denote the list of length $n$ whose coordinates are all $0$:

\[
  \mathbf{0} = (0, 0, ..., 0)
\]

% ------------------------------
\section{1.11 Note: $\mathbf{C^1}$ can be thought of as a plane}
% ------------------------------

On page 6, below Example 1.11, the textbook says: ``Similarly, $\mathbf{C}^1$
can be thought of as a plane.''

It is so because $\mathbf{C}^1$ is the set of complex numbers, each of which
consists of two parts: the real part and the imaginary part. Both parts are real
numbers and they can form a 2D plane, hence ``as a plane''.

% ------------------------------
\section{1.12 Vectors}
% ------------------------------

For $x \in \mathbf{F}^n$, we can view it as a point in the space $\mathbf{F}^n$,
but we can also view it as an ``arrow'' in the same space. When we view it as
an ``arrow'', we refer to it as a \textbf{\textit{vector}}.

% ------------------------------
\section{1.13 Definition: \textit{addition} in $\mathbf{F}^n$}
% ------------------------------

Given

\[
  \mathbf{F^n} = \{(x_1, ..., x_n): x_j \in \mathbf{F} \ for \ j = 1, ..., n\}
\]

and two lists $x, y \in \mathbf{F}^n$, and

\[
  x = (x_1, x_2, ..., x_n)
\]
\[
  y = (y_1, y_2, ..., y_n)
\]

we have

\begin{equation*}
\begin{split}
  x + y &= (x_1, x_2, ..., x_n) + (y_1, y_2, ..., y_n) \\
        &= (x_1 + y_1, x_2 + y_2, ..., x_n + y_n)
\end{split}
\end{equation*}

The addition has the property of \textbf{\textit{commutativity}}: If $x, y \in
\mathbf{F}^n$, then $x + y = y + x$.

The \textbf{\textit{additive inverse}} of $x$, denoted as $-x$, is the vector
$-x \in \mathbf{F}^n$ such that

\[
  x + (-x) = 0
\]

In other words, if $x = (x_1, ..., x_n)$, then $-x = (-x_1, ..., -x_n)$.

% ------------------------------
\section{1.14 Definition:\
  \textbf{\textit{scalar multiplication}} in $\mathbf{F}^n$}
% ------------------------------

For $\lambda \in \mathbf{F}$ and $(x_1, ..., x_n) \in \mathbf{F}^n$, we define

\[
  \lambda(x_1, ..., x_n) = (\lambda x_1, ..., \lambda x_n)
\]

% ------------------------------
\section{1.18 Definition: \it{addition}, \it{scalar multiplication}}
% ------------------------------

\begin{itemize}
  \item An \textbf{\textit{addition}} on a set $V$ is a function that assigns
    an element $u+v \in V$ to each pair of element $u, v \in V$.
  \item A \textbf{\textit{scalar multiplication}} on a set $V$ is a function
    that assigns an element $\lambda v \in V$ to each $\lambda \in \mathbf{F}$
    and each $v \in V$.
\end{itemize}

% ------------------------------
\section{1.19 Definition: \textbf{\textit{vector space}}}
% ------------------------------

A \textbf{\textit{vector space}} is a set $V$ along with an \textit{addition}
on $V$ and a \textit{scalar multiplication} on $V$ such that the following
properties hold:

\textbf{commutativity}: $u + v = v + u$ for all $u, v \in V$. \textbf{Note}
that it doesn't define the relationship between $uv$ and $uv$.

\textbf{associativity}: For all $u, v, w \in V$ and all $a, b \in \mathbf{F}$:
\begin{itemize}
  \item $(u + v) + w = u + (v + w)$
  \item $(ab)v = a(bv)$
\end{itemize}

\textbf{Note} that associativity doesn't define the relationship between
$(uv)w$ and $u(vw)$.

\textbf{additive identity}: For all $v \in V$, there exists an element $0 \in V$
such that $v + 0 = v$. \textbf{Note} this doesn't require uniqueness of $0$.

\textbf{additive inverse}: For all $v \in V$, there exists $w \in V$ such that
$v + w = 0$. \textbf{Note} this doesn't require uniqueness of $w$.

\textbf{multiplicative identity}: $1v = v$ for all $v \in V$. \textbf{Note}
  that $1 \in \mathbf{F}$.

\textbf{distributive properties}: For all $a, b \in \mathbf{F}$ and all $u, v
\in V$:
\begin{itemize}
  \item $a(u + v) = au + av$
  \item $(a + b)v = av + bv$
\end{itemize}

% ------------------------------
\section{Properties 1.25 - 1.31}
% ------------------------------

\begin{itemize}
  \item 1.25: Unique additive identity: A vector space has a unique additive
    identity.
  \item 1.26 Unique additive inverse: Every element in a vector space has a
    unique additive inverse.
  \item 1.27 Notation $-v$, $w - v$: Let $v, w \in V$, then:
    \begin{itemize}
      \item[$\bullet$] $-v$ denotes the additive inverse of $v$.
      \item[$\bullet$] $w - v$ is defined to be $w + (-v)$.
    \end{itemize}
  \item 1.28 Notation $V$: For the rest of the book, $V$ denotes a vector space
    over $\mathbf{F}$.
  \item 1.29 The number 0 times a vector: $0v = 0$ for every $v \in V$.
  \item 1.30 A number times the vector 0: $a0 = 0$ for every $a \in \mathbf{F}$.
  \item 1.31 The number $-1$ times a vector: $(-1)v = -v$ for every $v \in V$.
\end{itemize}

% ------------------------------
\section{1.20 Definition: \textbf{\textit{vector}}, \textbf{\textit{point}}}
% ------------------------------

Elements of a vector space are called \textbf{\textit{vector}} or
\textbf{\textit{point}}.

% ------------------------------
\section{My understanding of vector space}
% ------------------------------

\begin{itemize}
  \item Essentially, ``addition'' of two vectors is to connect the tail of the
    first vector with the head of the second vector.
  \item Essentially, ``scalar multiplication'' of a vector is to shrink or
    stretch the vector.
  \item The definition of \textit{vector space} is saying: For an arbitrary set
    $V$, we can define arbitrary operations called \textit{addition} and
    \textit{scalar multiplication} on the elements (assuming ``scalar'' makes
    sense in the context). However, not all the addition and scalar
    multiplication can make $V$ meet the properties that are required by vector
    space definition. In other occasions, $V$ may not include all the elements
    that make the addition and scalar multiplication meet the properties that
    are required by the vector space definition. Only those sets $V$ and the
    corresponding addition and scalar multiplication that meet those properties
    are called \textit{vector spaces}.
\end{itemize}

% ------------------------------
\section{1.23 Notation $F^S$}
% ------------------------------

\begin{itemize}
  \item If $S$ is a set, then $\mathbf{F}^S$ denotes the set of
    \textbf{functions} from $S$ to $\mathbf{F}$.
  \item For $f,g \in \mathbf{F}^S$, the \textbf{sum} $f + g \in \mathbf{F}^S$
    is the function defined by
      \[ (f + g)(x) = f(x) + g(x) \]
    for all $x \in S$.
  \item For $\lambda \in \mathbf{F}$ and $f \in \mathbf{F}^S$, the
    \textbf{product} $\lambda f \in \mathbf{F}^S$ is the function defined by
      \[ (\lambda f)(x) = \lambda f(x) \]
    for all $x \in S$.
\end{itemize}

% ------------------------------
\section{1.24 Example $\mathbf{F}^S$ is a vector space}
% ------------------------------

\begin{itemize}
  \item If $S$ is a \textbf{nonempty set}, then $\mathbf{F}^S$ (with the
   operations of addition and scalar multiplication as defined in section 1.23)
   is a vector space over $\mathbf{F}$.
  \item The additive identity of $\mathbf{F}^S$ is the function $0:
    S \rightarrow \mathbf{F}$ defined by
      \[ 0(x) = 0 \]
    for all $x \in S$.
  \item For $f \in \mathbf{F}^S$, the additive inverse of $f$ is the function
    $-f: S \rightarrow \mathbf{F}$ defined by
      \[ (-f)(x) = -f(x) \]
    for all $x \in S$.
\end{itemize}

% ------------------------------
\section{My understanding of $\mathbf{F}^S$} \label{F^S understanding}
% ------------------------------

\begin{enumerate}
  \item Note that the elements in $\mathbf{F}^S$ are \textbf{functions}.
    According to the definition of $\mathbf{F}^S$, the only condition these
    functions must satisfy is they map from $S$ to $\mathbf{F}$.
  \item It's also important to note that it doesn't matter how the mapping from
    $S$ to $\mathbf{F}$ is defined. For example, it doesn't say that every
    element in $S$ must be mapped to a different element on $\mathbf{F}$. In
    fact, it's possible that all the element in $S$ are just mapped to one
    element in $\mathbf{F}$. Again, the point is the mapping itself does not
    matter, as long as the mapping is from $S$ to $\mathbf{F}$.
  \item \label{mapping rules} Because the mapping rule doesn't matter, that
    means \textbf{all possible mappings} (i.e., all possible functions) from
    $S$ to $\mathbf{F}$ are included in $\mathbf{F}^S$. For example:
    \begin{enumerate}
      \item Function $f_1: x \rightarrow x$ for all $x \in S$
      \item Function $f_2: x \rightarrow x + 1.339$ for all $x \in S$
      \item Function $f_3: x \rightarrow 2x^3 + 9\pi$ for all $x \in S$
      \item Function $f_4: x \rightarrow 1$ for all $x \in S$
      \item Function $f_5:$
        \[
          x \rightarrow \begin{cases}
            1, & if x = 13.5 \\
            0,  & if x \neq 13.5 \\
          \end{cases}
        \]
        for all $x \in S$.
      \item Function $f_6: x \rightarrow 0$ for all $x \in S$
      \item etc.
    \end{enumerate}
    Notice that $f_6$ is the \textbf{additive identity} in $\mathbf{F}$.
  \item The type of elements of $S$ doesn't matter either, according to the
    definition. For example, the elements in $S$ don't have to be numbers. They
    can be shapes like $\{ \clubsuit, \diamondsuit, \heartsuit, \spadesuit \}$.
  \item The textbook says $\mathbf{F}^n$ and $\mathbf{F}^{\infty}$ can be
    viewed as special cases of $\mathbf{F}^S$. This is correct but the textbook
    doesn't explain everything about them:
    \begin{itemize}
      \item In these two cases, $S$ is the set $\{ 1, 2, \ldots, n \}$ and
      $\{ 1, 2, \ldots, \}$, respectively.
      \item An element in $\mathbf{F}^n$, i.e., $\{ x_1, x_2, \ldots, x_n \}$,
        is written as a list but represents a \textbf{function}. Yes, we
        usually use the symbol $f$ to denote a function, but we don't have to.
        If we want to, we can choose any arbitrary symbols to denote functions,
        including using a list. In the case of $\mathbf{F}^n$, the list
        $\{ x_1, x_2, \ldots, x_n \}$ and $\{ y_1, y_2, \ldots, y_n \}$ can be
        used to denote two different functions, just in the same way that $f$
        and $g$ can denote different functions.
    \end{itemize}
\end{enumerate}

% ------------------------------
\section{Review Question Answers}
% ------------------------------

\begin{enumerate}
  \item See definition 1.19 in the textbook.
  \item $\mathbf{F}^n$ is just one concrete vector space, while $V$ can
    represent any vector space.
  \item The relationship is not defined. The vector space definition only
    defines commutativity for the addition on $u$ and $v$, but not the
    communtativity on the multiplication.
  \item The relationship is not defined. The vector space definition only
    defines associativity on addition and scalar multiplication, but not on
    the general multiplication of vectors inside the vector space.
  \item Because the definition of vector space depends on scalar multiplication
    which then depends on the scalar set $\mathbf{F}$. The elements in
    $\mathbf{F}$ participate the scalar multiplication which is part of vector
    space definition.
  \item See definition 1.23 in the textbook.
  \item $S$ stands for the set of the variable (i.e., the input parameter). An
    element in $\mathbf{F}^S$ is a function that maps from $S$ to $\mathbf{F}$.
  \item See the section \ref{F^S understanding}, item \ref{mapping rules}.
    \item Because the scalar multiplication in section 1.17 is only defined for
    $\mathbf{F}^n$, but the property ``1.29 The number 0 times a vector'' is a
    general property in any vector space $V$ which does not have to be
    $\mathbf{F}^n$. When $V$ is not $\mathbf{F}^n$, the scalar multiplication
    in section 1.17 may not make sense at all.
  \item See definition 1.32 in the textbook.
  \item See section 1.34 in the textbook.
  \item The three conditions for the subset $U$ are all about the elements and
    arithmetic operations on it. The multiplicative identity $1$ belongs to the
    set $\mathbf{F}$ (which is implied in the textbook due to notation 1.28),
    so the multiplicative identity has nothing to do with $U$, so it is not
    mentioned in the three conditions.
 \end{enumerate}

% ------------------------------
\section{Progress tracker}
% ------------------------------

As of 2023-02-21, I'm on page 10: Digression on Fields

\chapter*{References}
\addcontentsline{toc}{chapter}{References}

\begin{itemize}
  \item $[1]$ \href{https://linear.axler.net/}{Sheldon Axler: \it{Linear Algebra Done Right}}
  \item $[2]$ \href{https://bookstore.ams.org/view?ProductCode=CHEL/79}{Edmund Landau: \it{Foundations of Analysis}}
\end{itemize}

\end{document}
