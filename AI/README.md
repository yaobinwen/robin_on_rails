# Artificial Intelligence

- Many people use ChatGPT to generate code. I doubt if that's the best way to use it and how this kind of use can affect cognitive ability. It's like we stop using part of our mind and that part will get rusty. I think ChatGPT helps the best in learning new knowledge.
- [Use of nuclear and radiological weapons by terrorists?](https://international-review.icrc.org/sites/default/files/irrc_859_5.pdf)
- [Can Terrorists Build Nuclear Weapons?](https://www.nci.org/k-m/makeab.htm)

---

## Should AI be under human control?

Searching key words "should ai be under human's control":
- [On the purpose of meaningful human control of AI](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9868906/)
- [The Future of Human Agency](https://www.pewresearch.org/internet/2023/02/24/the-future-of-human-agency/)
- [Can the development of artificial intelligence and robotics escape the human control?](https://www.researchgate.net/post/Can-the-development-of-artificial-intelligence-and-robotics-escape-the-human-control)
- [Ensuring Human Control over AI-Infused Systems](https://www.nationalacademies.org/news/2022/04/ensuring-human-control-over-ai-infused-systems)
- [Should Artificial Intelligence Be Regulated?](https://issues.org/perspective-artificial-intelligence-regulated/)
- [Who is controlling whom? Reframing “meaningful human control” of AI systems in security](https://link.springer.com/article/10.1007/s10676-023-09686-x)
- [Should We Stop Developing AI For The Good Of Humanity?](https://www.forbes.com/sites/bernardmarr/2023/05/03/should-we-stop-developing-ai-for-the-good-of-humanity/?sh=7191bfb82943)
- [Artificial Intelligence and the Future of Humans](https://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/)
- [Giving AI direct control over anything is a bad idea – here’s how it could do us real harm](https://theconversation.com/giving-ai-direct-control-over-anything-is-a-bad-idea-heres-how-it-could-do-us-real-harm-210168)
- [The AI Control Problem (and why you should know about it)](https://wearebrain.com/blog/the-ai-control-problem-and-why-you-should-know-about-it)
- [There is no proof that AI can be controlled, according to extensive survey](https://www.eurekalert.org/news-releases/1032090)
- [AI—The good, the bad, and the scary](https://eng.vt.edu/magazine/stories/fall-2023/ai.html)
- [Experts say humans could be wrestling AI for control by 2035](https://aimagazine.com/articles/experts-say-humans-could-be-wrestling-ai-for-control-by-2035)
- [AI Should Augment Human Intelligence, Not Replace It](https://hbr.org/2021/03/ai-should-augment-human-intelligence-not-replace-it)
- [Human control of artificial intelligence](https://www.tudelft.nl/en/delft-outlook/articles/human-control-of-artificial-intelligence)
- [Why Experts Say We Should Control AI, Now](https://www.lifewire.com/why-experts-say-we-should-control-ai-now-5095953)
- [12 Risks and Dangers of Artificial Intelligence (AI)](https://builtin.com/artificial-intelligence/risks-of-artificial-intelligence)
- [The impact of artificial intelligence on human society and bioethics](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7605294/)
- [Maintaining Control Over AI](https://issues.org/debating-human-control-over-artificial-intelligence-forum-shneiderman/)

---

## Logic-based artificial intelligence

- [Logic-Based Artificial Intelligence](https://plato.stanford.edu/entries/logic-ai/)

---

A few days ago, [Cognition](https://twitter.com/cognition_labs) introduced ["Devin, the first AI software engineer"](https://twitter.com/cognition_labs/status/1767548763134964000). Being a software engineer myself, this kind of news seems to be very bad news to me.

On the surface, it looks like there will be a job crisis to most, if not all, of the software engineers. But I believe there is an opportunity inside a crisis: The development of A.I. pushes us to rethink of the meaning of life, so this is probably the best opportunity to find the thing that really matters.

When asked, a lot of people may say the source of the meaning of their lives is to "make the world a better place." In other words, the world is not good enough yet and they believe their work can improve the situation. But what if A.I. is advanced enough and can do all the needed work, as long as they receive the command from the human beings? In that case, there would be no room for people to do anything. If they can't do anything, how do they find the meaning of their lives?

But AI may not be able to do "all" the work: AI may help do a lot of technical work, but when it comes to human relationships, we still need human beings themselves.

---

Do we need to understand the code that AI writes? It seems so. We probably need to understand what AI is doing. Otherwise, we can be easily deceived and manipulated by AI and just blindly trust them, giving them the opportunities to rule us. For example, if AI causes some damage and then tells us the damage is the inherent risk of the thing, how do we know AI is telling the truth or deceiving us?

Another example: Suppose AI #1 writes a piece of text that we human beings don't understand. So we ask AI #2 to translate it. AI #2 does it. But how do we know AI #2 translates it correctly, and does not secretly work with AI #1 to deceive us?

---

Many people have ideas of solving problems but don't know technologies; many people have technological knowledge but don't know what problems to solve. AI helps the first kind of people so they have more access to technological knowledge and thus can do more. Therefore, people need to focus on finding the right problems to solve.

---

How to guarantee that human beings are always the master of AI?

---

When AI can replace the human beings on a massive scale, i.e., most of the people can't make money because they can't find a job now, how to maintain their living?

Likewise, when AI can make more fortune than human beings do, how to distribute the fortune?

---

Can AI make more AIs?
