# Thoughts

---

设想：假如未来的机器人需要执行阿西莫夫的机器人三大定律，那么这样的机器人可以被人用来当作军队吗？如果对手是机器人，则应该可以；但是如果对手是人(比如在实行武力镇压的时候)，则不可以，因为机器人被设定成不能伤害人。所以，有权力的人一定会设定独特的规则，让某些受自己控制的机器人可以伤害人。相应的，反抗力量则会选择制造机器人去反抗。所以可能会有机器人之间的战争。《终结者》其实描述的就是类似的一个故事。

---

一些关于AI的想法：

- 如果AI发展到人类智能级别，那么人类是否还有必要思考？那个时候，人类是否会面临更严重的“人生意义”危机？如果还有必要思考，那么人类需要思考什么？
- 个人AI(Personal AI)在未来一定是主流。其实现在的Siri或者Alexa就是一种个人AI。和计算机不同的是，计算机最初是藉由国家力量建造出来的设备，然后才慢慢渗透到家庭和个人领域。而AI从一开始就是在国家和个人两个层面同时发展的。
- AI在未来可能会成为一个全球化的基础设施。与此同时，每个人都有一个属于自己的“AI实例”，成为他的个人助手。所有的“AI实例”都共享同一个数据库。但这里有几个问题：
  - 假如有一个全球的AI数据库，那么通过共享这个数据库，全球所有的人都可以使用同等级别智能的服务，在这个层面上，不同阶层的人之间没有不公平。
  - 但国家在那个时候是一个什么概念？国家和国家之间为了竞争的需要，会同意把自己国家的资源上传到全球数据库中和别的国家共享吗？(人的自私本质)
  - 全球共享一个AI系统可以消除不公，但是一旦系统出问题，则全人类都会受到影响。(标准化和客制化之间的矛盾；见《机械公敌》(_I, Robot_))。
- 关于AI和道德系统：
  - AI的本质是计算机算法。计算机算法本质上是量化的(quantitative)，那么是不是说AI在道德层面会更容易形成功利主义(utilitarianism)的道德观念？
  - 假如AI采纳了功利主义(或有这个倾向的道德观念)，那么当人类对其下达的指令所造成的损失比它自己计算出的某个指令所造成的损失要大，那么AI应该拒绝人类指令吗？
- Artificial Intelligence一定要仿照人类的大脑进行思考吗？AI是否可以有自己独特的思考方式？
- 未来的AI因为具有比人类更强的学习能力和更大的信息储备，它们完全可以成为人类的mentor。人们会和AI谈论自己的目标，然后AI辅助他们去实现。在我的故事里，这个AI产品的名字可以叫Mel，然后他们的生产商的宣传口号是："Mel, the greatest mentor in the world!"

---

2018年5月12日：今天读了[Guide to Living with AI, Robots, Algorithms and Altcoins](https://medium.com/futuresin/guide-to-living-with-ai-robots-algorithms-and-altcoins-5d1561f4cf32)一文。作者在文中提问到：

> Or the fact that our young people are reading less, and are less curious about the world than previous generations? Is technology continuing to divorce us from nature, or helping us know ourselves better?

我个人目前觉得，未来未必那么悲观。如果人工智能和机器人真得能够极大地提高生产效率的话，那么可能很多人都不必去工作也可以获得足够支持自己生活的资源，那么那个时候，他们可以不必去上班，至少很大程度上不必去做重复性的无聊的工作，多余的时间他们可以用来做自己感兴趣的事情或者探索更广阔的世界；他们可能有更多的时间锻炼身体、学习乐器；他们可能可以有更多的时间和家人朋友在一起；他们可能可以有更多的时间去阅读自己曾经没有时间和精力去读的书，在书里和先贤做精神上的对话。

不过，这也启发我去想：什么样的人工智能会导致人们的生活质量下降？Elon Musk所担心的会危害人类的人工智能具有什么特征？

In contrast, in an article written by Kai-Fu Lee, [A BLUEPRINT FOR COEXISTENCE WITH ARTIFICIAL INTELLIGENCE](https://www.wired.com/story/a-blueprint-for-coexistence-with-artificial-intelligence/), he envisions an enlightening future of the artificial intelligence which helps humankind live a life of higher quality.

---

这个故事的内核是：人是否可以与人工智能建立感情联结？如果人们知道与自己交谈的是一个人工智能算法，他们很可能不会和对方建立如同朋友一般的感情联结。人们更愿意和真实的人类建立感情纽带。但是我们似乎却可以和一个完全没有见过的、网络上的人建立起感情联结，并有可能把对方视为自己的知己和挚友。可是，如果两个人从未谋面，一个人如何判断对方一定是一个人类而不是人工智能呢？

这个故事可能有两个发展方向。一个方向是人类坚持只和另一个人类建立感情联结，一旦他发现对方不是真实的人类，那么TA会中断或者将这种感情的亲密度降级。在人工智能高度发达的未来社会，寻求对方真实的身份验证可能成为了每个人需要做的一件事。另一个方向是人类认可了人工智能的情感属性，并且不介意和人工智能建立情感联结。为了达到这个级别的模拟，人工智能必须具有感情，例如欢乐、痛苦、和忧伤。但是一旦人工智能拥有了人类的感情，那么要求人工智能全天24小时不停地工作是否会涉及到“奴役”的问题(因为AI可能会模拟出疲劳、乏味的感觉，而这些感觉是人类所具有的，根据前面的限定条件，AI需要能模拟人类的所有感情)？
