# Artificial Intellegence

## Overview

This folder has the notes taken from learning artificial intelligence.

AI is divided broadly into three stages: `artificial narrow intelligence` (ANI), `artificial general intelligence` (AGI) and `artificial super intelligence` (ASI). [AIO-5]

## Names

- [John McCarthy](http://jmc.stanford.edu/index.html): Father of AI who coined the term "Artificial Intelligence".
- [Supasorn Suwajanakorn](http://www.supasorn.com/): The one who created the AI version of politicians.
- [Max Tegmark](http://space.mit.edu/home/tegmark/): An AI expert in MIT, author of [_Life 3.0: Being Human in the Age of Artificial Intelligence_](https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598).
- [Kevin Frans](http://kvfrans.com/), a [TED 2018 speaker](https://ted2018.ted.com/speakers#kevin-frans), a high school student (2018) who developed a method for "training AI agents to solve many tasks at the same time, by learning a hierarchy of smaller strategies." (后生可畏，我是不是应该考虑做点别的事情了……)

## References

- Artificial Intelligence Overview (AIO)
  - [AIO-1] [What is AI? / Branches of AI](http://jmc.stanford.edu/artificial-intelligence/what-is-ai/branches-of-ai.html)
  - [AIO-2] [Artificial Intelligence: Overview](http://www.hutter1.net/ai/sintro2ai.pdf)
  - [AIO-3] [Artificial Intelligence Industry – An Overview by Segment](https://www.techemergence.com/artificial-intelligence-industry-an-overview-by-segment/)
  - [AIO-4] [Understanding the Four Types of Artificial Intelligence](http://www.govtech.com/computing/Understanding-the-Four-Types-of-Artificial-Intelligence.html)
  - [AIO-5] [The evolution of artificial intelligence](https://www.ubs.com/microsites/artificial-intelligence/en/new-dawn.html)
- AI Ethics (Eth)
  - [Eth-1] [CMU - K&L Gates Conference on Ethics and AI (webcast)](https://www.cmu.edu/ethics-ai/agenda/webcast.html)
- Machine Morality (MM)
  - [MM-1] [Moral Machine](http://moralmachine.mit.edu/)
- TED Talks (TT)
  - [TT-1] [The TED talks on the topic of AI](https://www.ted.com/topics/ai)

## Isaac Asimov's Books

A chronology of events in Isaac Asimov's positronic robot and Foundation stories: [Johnny Pez's Insanely Complete Fiction List](http://www.asimovonline.com/oldsite/insane_list.html)

## Just Some Ideas

--

设想：假如未来的机器人需要执行阿西莫夫的机器人三大定律，那么这样的机器人可以被人用来当作军队吗？如果对手是机器人，则应该可以；但是如果对手是人(比如在实行武力镇压的时候)，则不可以，因为机器人被设定成不能伤害人。所以，有权力的人一定会设定独特的规则，让某些受自己控制的机器人可以伤害人。相应的，反抗力量则会选择制造机器人去反抗。所以可能会有机器人之间的战争。《终结者》其实描述的就是类似的一个故事。

--

一些关于AI的想法：

- 如果AI发展到人类智能级别，那么人类是否还有必要思考？那个时候，人类是否会面临更严重的“人生意义”危机？如果还有必要思考，那么人类需要思考什么？
- 个人AI(Personal AI)在未来一定是主流。其实现在的Siri或者Alexa就是一种个人AI。和计算机不同的是，计算机最初是藉由国家力量建造出来的设备，然后才慢慢渗透到家庭和个人领域。而AI从一开始就是在国家和个人两个层面同时发展的。
- AI在未来可能会成为一个全球化的基础设施。与此同时，每个人都有一个属于自己的“AI实例”，成为他的个人助手。所有的“AI实例”都共享同一个数据库。但这里有几个问题：
  - 假如有一个全球的AI数据库，那么通过共享这个数据库，全球所有的人都可以使用同等级别智能的服务，在这个层面上，不同阶层的人之间没有不公平。
  - 但国家在那个时候是一个什么概念？国家和国家之间为了竞争的需要，会同意把自己国家的资源上传到全球数据库中和别的国家共享吗？(人的自私本质)
  - 全球共享一个AI系统可以消除不公，但是一旦系统出问题，则全人类都会受到影响。(标准化和客制化之间的矛盾；见《机械公敌》(_I, Robot_))。
- 关于AI和道德系统：
  - AI的本质是计算机算法。计算机算法本质上是量化的(quantitative)，那么是不是说AI在道德层面会更容易形成功利主义(utilitarianism)的道德观念？
  - 假如AI采纳了功利主义(或有这个倾向的道德观念)，那么当人类对其下达的指令所造成的损失比它自己计算出的某个指令所造成的损失要大，那么AI应该拒绝人类指令吗？
- Artificial Intelligence一定要仿照人类的大脑进行思考吗？AI是否可以有自己独特的思考方式？
